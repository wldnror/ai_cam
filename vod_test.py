#!/usr/bin/env python3
import warnings
warnings.filterwarnings("ignore")  # ëª¨ë“  íŒŒì´ì¬ ê²½ê³  ì–µì œ

import logging
logging.getLogger('ultralytics').setLevel(logging.WARNING)
logging.getLogger('torch').setLevel(logging.WARNING)
logging.getLogger('werkzeug').setLevel(logging.ERROR)

import os
import time
import threading
import queue
import subprocess
import pickle
import atexit

import cv2
import numpy as np
import torch
import psutil
from PIL import Image, ImageDraw, ImageFont
from flask import Flask, Response, render_template, jsonify, request

# ìºì‹œ íŒŒì¼ ê²½ë¡œ
CACHE_PATH = '/home/user/cache.pkl'

# 0) ìºì‹œ ë¡œë“œ: ìž¬ë¶€íŒ… í›„ì—ë„ ì‚¬ìš©
try:
    with open(CACHE_PATH, 'rb') as f:
        detection_cache, repeat_count = pickle.load(f)
        print("âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ")
except Exception:
    detection_cache = {}
    repeat_count     = {}

# ì¢…ë£Œ ì§ì „ ìºì‹œ ì €ìž¥
@atexit.register
def save_on_exit():
    try:
        with open(CACHE_PATH, 'wb') as f:
            pickle.dump((detection_cache, repeat_count), f)
        print("ðŸ’¾ ì¢…ë£Œ ì§ì „ ìºì‹œ ì €ìž¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ìºì‹œ ì €ìž¥ ì‹¤íŒ¨: {e}")

# 1) PyTorch ëª¨ë¸ ë¡œë“œ (4ë‹¨ê³„)
torch.set_num_threads(1)
torch.set_num_interop_threads(1)
model_fast   = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True).eval()
model_refine = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).eval()
model_heavy  = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True).eval()

# 2) ìºì‹œ, ìž¬ìƒ íšŸìˆ˜, ë‹¨ê³„ ì„¤ì •
STAGE_CONFIG = {
    1: {'size': (160, 90),   'model': model_fast,   'thresh': 0.80},  # ì´ˆì €í•´ìƒë„
    2: {'size': (320, 180),  'model': model_fast,   'thresh': 0.65},  # ì €í•´ìƒë„
    3: {'size': (640, 360),  'model': model_refine, 'thresh': 0.50},  # ì¤‘ê°„í•´ìƒë„
    4: {'size': (1280, 720), 'model': model_heavy,  'thresh': 0.50},  # ì›ë³¸ í•´ìƒë„
}
MAX_STAGE = 4
skip_interval = 2

detection_cache = detection_cache
repeat_count     = repeat_count

# 3) ë ˆì´ë¸” ë§¤í•‘ ë° í°íŠ¸ ì„¤ì •
label_map = {'person': 'ì‚¬ëžŒ', 'car': 'ìžë™ì°¨'}
font_paths = [
    '/usr/share/fonts/truetype/noto/NotoSansCJKkr-Regular.otf',
    '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
    '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
]
font = None
for path in font_paths:
    if os.path.isfile(path):
        try:
            font = ImageFont.truetype(path, 24)
            print(f"âœ… í°íŠ¸ ë¡œë“œ: {path}")
            break
        except OSError:
            continue
if font is None:
    print("âš ï¸ ì‚¬ìš©í•  í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    font = ImageFont.load_default()

# 4) ì¹´ë©”ë¼ ì¸í„°íŽ˜ì´ìŠ¤ ì •ì˜
class CSICamera:
    def __init__(self):
        from picamera2 import Picamera2
        self.picam2 = Picamera2()
        config = self.picam2.create_video_configuration(
            main={"size": (1280, 720)}, lores={"size": (640, 360)}, buffer_count=2
        )
        self.picam2.configure(config)
        self.picam2.start()
        for _ in range(3): self.picam2.capture_array("main")
    def read(self):
        return True, self.picam2.capture_array("main")

class USBCamera:
    def __init__(self):
        self.cap = None
        for i in range(5):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                for _ in range(5): cap.read()
                self.cap = cap
                break
        if self.cap is None:
            raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ USB ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    def read(self):
        return self.cap.read()

class VideoFileCamera:
    def __init__(self, path):
        self.cap = cv2.VideoCapture(path)
        if not self.cap.isOpened():
            raise RuntimeError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
    def read(self):
        ret, frame = self.cap.read()
        if not ret:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame = self.cap.read()
        return ret, frame

# 5) ì¹´ë©”ë¼ ì„ íƒ
video_path = os.path.expanduser('~/Desktop/1.mp4')
if os.path.isfile(video_path):
    camera = VideoFileCamera(video_path)
    use_file = True
    print(f">>> ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©: {video_path}")
else:
    try:
        camera = CSICamera()
        use_file = False
        print(">>> CSI ì¹´ë©”ë¼ ëª¨ë“ˆ ì‚¬ìš©")
    except:
        camera = USBCamera()
        use_file = False
        print(">>> USB ì›¹ìº  ì‚¬ìš©")

# 6) ì£¼ê¸°ì  ìºì‹œ ì €ìž¥ ìŠ¤ë ˆë“œ
threading.Thread(target=lambda: (time.sleep(60), pickle.dump((detection_cache, repeat_count), open(CACHE_PATH,'wb')), print("ðŸ’¾ ì£¼ê¸°ì  ìºì‹œ ì €ìž¥ ì™„ë£Œ")), daemon=True).start()

# 7) í”„ë ˆìž„ ì²˜ë¦¬ ë° í
frame_queue = queue.Queue(maxsize=1)

def capture_and_process():
    fps = 10
    interval = 1.0 / fps
    frame_count = 0
    last_results = None

    while True:
        start = time.time()
        ret, frame = camera.read()
        if not ret:
            continue

        frame_count += 1
        if frame_count % skip_interval != 0 and last_results is not None:
            results, infer_size = last_results
        else:
            frame_idx = int(camera.cap.get(cv2.CAP_PROP_POS_FRAMES)) if use_file else frame_count
            repeat_count[frame_idx] = repeat_count.get(frame_idx, 0) + 1
            desired_stage = min(repeat_count[frame_idx], MAX_STAGE)

            cached = detection_cache.get(frame_idx)
            use_cached = False
            if cached:
                _, _, cached_stage, cached_conf = cached
                if cached_stage >= desired_stage:
                    if desired_stage == MAX_STAGE or cached_conf >= STAGE_CONFIG[desired_stage]['thresh']:
                        use_cached = True
            if use_cached:
                results, infer_size, _, _ = cached
            else:
                cfg = STAGE_CONFIG[desired_stage]
                inp = cv2.resize(frame, cfg['size'])
                with torch.no_grad():
                    res = cfg['model'](inp)
                confs = res.xyxy[0][:,4]
                max_conf = confs.max().item() if confs.numel()>0 else 0.0
                results = res
                infer_size = cfg['size']
                detection_cache[frame_idx] = (results, infer_size, desired_stage, max_conf)

        last_results = (results, infer_size)

        pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil)
        h_ratio = frame.shape[0] / infer_size[1]
        w_ratio = frame.shape[1] / infer_size[0]
        for *box, conf, cls in results.xyxy[0]:
            if conf < 0.20: continue
            x1, y1, x2, y2 = map(int, (box[0]*w_ratio, box[1]*h_ratio, box[2]*w_ratio, box[3]*h_ratio))
            label_en = results.names[int(cls)]
            label_ko = label_map.get(label_en)
            if label_ko:
                text = f"{label_ko} {conf.item()*100:.1f}%"
                color = (255,0,0) if label_en=='car' else (0,0,255)
                draw.rectangle([x1,y1,x2,y2], outline=color, width=2)
                draw.text((x1, y1-30), text, font=font, fill=color)

        frame_out = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
        _, buf = cv2.imencode('.jpg', frame_out, [int(cv2.IMWRITE_JPEG_QUALITY),80])
        data = buf.tobytes()
        if not frame_queue.empty():
            try: frame_queue.get_nowait()
            except queue.Empty: pass
        frame_queue.put(data)

        elapsed = time.time() - start
        time.sleep(max(0, interval - elapsed))

threading.Thread(target=capture_and_process, daemon=True).start()

# 8) Flask ì•±
app = Flask(__name__)

def generate():
    while True:
        frame = frame_queue.get()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    resp = Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame', direct_passthrough=True)
    resp.headers.update({'Cache-Control':'no-cache, no-store, must-revalidate','Pragma':'no-cache','Expires':'0'})
    return resp

@app.route('/stats')
def stats():
    cpu = psutil.cpu_percent(interval=0.5)
    mem = psutil.virtual_memory()
    temp = None
    try: temp = float(open('/sys/class/thermal/thermal_zone0/temp').read())/1000.0
    except: pass
    signal = None
    try:
        out = subprocess.check_output(['iwconfig','wlan0'], stderr=subprocess.DEVNULL).decode()
        for part in out.split():
            if part.startswith('level='): signal=int(part.split('=')[1])
    except: pass
    return jsonify({'cpu_percent':cpu,'memory_percent':mem.percent,'temperature_c':temp,'wifi_signal_dbm':signal})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
