#!/usr/bin/env python3
import warnings
warnings.filterwarnings("ignore")  # Î™®Îì† ÌååÏù¥Ïç¨ Í≤ΩÍ≥† ÏñµÏ†ú

import logging
logging.getLogger('ultralytics').setLevel(logging.WARNING)
logging.getLogger('torch').setLevel(logging.WARNING)
logging.getLogger('werkzeug').setLevel(logging.ERROR)

import os
import time
import threading
import queue
import subprocess
import pickle
import atexit
import json

import cv2
import numpy as np
import torch
import psutil
from PIL import Image, ImageDraw, ImageFont
from flask import Flask, Response, render_template, jsonify, request

# Ï∫êÏãú Î∞è repeat JSON Í≤ΩÎ°ú
CACHE_PATH = '/home/user/cache.pkl'
REPEAT_PATH = '/home/user/repeat_count.json'

# 0) Ï∫êÏãú Î°úÎìú: Ïû¨Î∂ÄÌåÖ ÌõÑÏóêÎèÑ ÏÇ¨Ïö©
try:
    with open(CACHE_PATH, 'rb') as f:
        detection_cache, repeat_count = pickle.load(f)
        print("‚úÖ Ï∫êÏãú Î°úÎìú ÏôÑÎ£å")
except Exception:
    detection_cache = {}
    repeat_count = {}

# repeat_count JSON Ï†ÄÏû•Ìï®Ïàò
def save_repeat_json():
    try:
        with open(REPEAT_PATH, 'w') as f:
            json.dump(list(repeat_count.keys()), f)
    except Exception as e:
        print(f"‚ö†Ô∏è repeat_count JSON Ï†ÄÏû• Ïã§Ìå®: {e}")

# Ï¢ÖÎ£å ÏßÅÏ†Ñ Ï∫êÏãú Î∞è JSON Ï†ÄÏû•
@atexit.register
def save_on_exit():
    try:
        with open(CACHE_PATH, 'wb') as f:
            pickle.dump((detection_cache, repeat_count), f)
        save_repeat_json()
        print("üíæ Ï¢ÖÎ£å ÏßÅÏ†Ñ Ï∫êÏãú Î∞è JSON Ï†ÄÏû• ÏôÑÎ£å")
    except Exception as e:
        print(f"‚ö†Ô∏è Ï∫êÏãú Ï†ÄÏû• Ïã§Ìå®: {e}")

# 1) PyTorch Î™®Îç∏ Î°úÎìú (4Îã®Í≥Ñ)
torch.set_num_threads(1)
torch.set_num_interop_threads(1)
model_fast   = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True).eval()
model_refine = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).eval()
model_heavy  = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True).eval()

# 2) Îã®Í≥Ñ ÏÑ§Ï†ï
STAGE_CONFIG = {
    1: {'size': (160, 90),   'model': model_fast,   'thresh': 0.80},  # Ï¥àÏ†ÄÌï¥ÏÉÅÎèÑ
    2: {'size': (320, 180),  'model': model_fast,   'thresh': 0.65},  # Ï†ÄÌï¥ÏÉÅÎèÑ
    3: {'size': (640, 360),  'model': model_refine, 'thresh': 0.50},  # Ï§ëÍ∞ÑÌï¥ÏÉÅÎèÑ
    4: {'size': (1280, 720), 'model': model_heavy,  'thresh': 0.50},  # ÏõêÎ≥∏ Ìï¥ÏÉÅÎèÑ
}
MAX_STAGE = 4
skip_interval = 2

# Ïû¨ÏÇ¨Ïö© Í∞ùÏ≤¥
# detection_cache, repeat_count

detection_cache = detection_cache
repeat_count = repeat_count

# 3) Î†àÏù¥Î∏î Îß§Ìïë Î∞è Ìè∞Ìä∏ ÏÑ§Ï†ï
label_map = {'person': 'ÏÇ¨Îûå', 'car': 'ÏûêÎèôÏ∞®'}
font_paths = [
    '/usr/share/fonts/truetype/noto/NotoSansCJKkr-Regular.otf',
    '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
    '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
]
font = None
for path in font_paths:
    if os.path.isfile(path):
        try:
            font = ImageFont.truetype(path, 24)
            print(f"‚úÖ Ìè∞Ìä∏ Î°úÎìú: {path}")
            break
        except OSError:
            continue
if font is None:
    print("‚ö†Ô∏è ÏÇ¨Ïö©Ìï† ÌïúÍ∏Ä Ìè∞Ìä∏Î•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. Í∏∞Î≥∏ Ìè∞Ìä∏Î°ú ÎåÄÏ≤¥Ìï©ÎãàÎã§.")
    font = ImageFont.load_default()

# 4) Ïπ¥Î©îÎùº Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ï†ïÏùò
class CSICamera:
    def __init__(self):
        from picamera2 import Picamera2
        self.picam2 = Picamera2()
        cfg = self.picam2.create_video_configuration(
            main={"size": (1280, 720)}, lores={"size": (640, 360)}, buffer_count=2
        )
        self.picam2.configure(cfg)
        self.picam2.start()
        for _ in range(3): self.picam2.capture_array("main")
    def read(self):
        return True, self.picam2.capture_array("main")

class USBCamera:
    def __init__(self):
        self.cap = None
        for i in range(5):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                for _ in range(5): cap.read()
                self.cap = cap
                break
        if self.cap is None:
            raise RuntimeError("ÏÇ¨Ïö© Í∞ÄÎä•Ìïú USB ÏõπÏ∫†ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
    def read(self):
        return self.cap.read()

class VideoFileCamera:
    def __init__(self, path):
        self.cap = cv2.VideoCapture(path)
        if not self.cap.isOpened():
            raise RuntimeError(f"ÎπÑÎîîÏò§ ÌååÏùºÏùÑ Ïó¥ Ïàò ÏóÜÏäµÎãàÎã§: {path}")
    def read(self):
        ret, frame = self.cap.read()
        if not ret:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame = self.cap.read()
        return ret, frame

# 5) Ïπ¥Î©îÎùº ÏÑ†ÌÉù
video_path = os.path.expanduser('~/Desktop/1.mp4')
if os.path.isfile(video_path):
    camera = VideoFileCamera(video_path)
    use_file = True
    print(f">>> ÎπÑÎîîÏò§ ÌååÏùº ÏÇ¨Ïö©: {video_path}")
else:
    try:
        camera = CSICamera()
        use_file = False
        print(">>> CSI Ïπ¥Î©îÎùº Î™®Îìà ÏÇ¨Ïö©")
    except:
        camera = USBCamera()
        use_file = False
        print(">>> USB ÏõπÏ∫† ÏÇ¨Ïö©")

# 6) Ï£ºÍ∏∞Ï†Å Ï∫êÏãú Î∞è JSON Ï†ÄÏû• Ïä§Î†àÎìú
threading.Thread(target=lambda: (time.sleep(60), 
                                 pickle.dump((detection_cache, repeat_count), open(CACHE_PATH,'wb')), 
                                 save_repeat_json(), 
                                 print("üíæ Ï£ºÍ∏∞Ï†Å Ï∫êÏãú Î∞è JSON Ï†ÄÏû• ÏôÑÎ£å")),
                  daemon=True).start()

# 7) ÌîÑÎ†àÏûÑ Ï≤òÎ¶¨ Î∞è ÌÅê
frame_queue = queue.Queue(maxsize=1)

def capture_and_process():
    fps = 10
    interval = 1.0 / fps
    frame_count = 0
    last_results = None

    while True:
        start = time.time()
        ret, frame = camera.read()
        if not ret:
            continue

        frame_count += 1
        # Ïä§ÌÇµ Ïù∏ÌÑ∞Î≤å Ï≤òÎ¶¨
        if frame_count % skip_interval != 0 and last_results:
            results, infer_size = last_results
        else:
            frame_idx = int(camera.cap.get(cv2.CAP_PROP_FRAME_COUNT if False else cv2.CAP_PROP_POS_FRAMES)) if use_file else frame_count
            repeat_count[frame_idx] = repeat_count.get(frame_idx, 0) + 1
            desired_stage = min(repeat_count[frame_idx], MAX_STAGE)

            cached = detection_cache.get(frame_idx)
            use_cached = False
            if cached:
                _, _, cstage, cconf = cached
                if cstage >= desired_stage and (desired_stage == MAX_STAGE or cconf >= STAGE_CONFIG[desired_stage]['thresh']):
                    use_cached = True
            if use_cached:
                results, infer_size, _, _ = cached
            else:
                cfg = STAGE_CONFIG[desired_stage]
                inp = cv2.resize(frame, cfg['size'])
                with torch.no_grad():
                    res = cfg['model'](inp)
                confs = res.xyxy[0][:,4]
                mconf = confs.max().item() if confs.numel()>0 else 0.0
                results = res
                infer_size = cfg['size']
                detection_cache[frame_idx] = (results, infer_size, desired_stage, mconf)
            save_repeat_json()

        last_results = (results, infer_size)

        # ÎùºÎ≤® Í∑∏Î¶¨Í∏∞
        pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil)
        h_ratio = frame.shape[0] / infer_size[1]
        w_ratio = frame.shape[1] / infer_size[0]
        for *box, conf, cls in results.xyxy[0]:
            if conf < 0.20: continue
            x1, y1, x2, y2 = map(int, (box[0]*w_ratio, box[1]*h_ratio, box[2]*w_ratio, box[3]*h_ratio))
            label_en = results.names[int(cls)]
            label_ko = label_map.get(label_en)
            if label_ko:
                text = f"{label_ko} {conf.item()*100:.1f}%"
                color = (255,0,0) if label_en=='car' else (0,0,255)
                draw.rectangle([x1,y1,x2,y2], outline=color, width=2)
                draw.text((x1, y1-30), text, font=font, fill=color)

        # Ï∂úÎ†•
        frame_out = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
        _, buf = cv2.imencode('.jpg', frame_out, [int(cv2.IMWRITE_JPEG_QUALITY),80])
        data = buf.tobytes()
        if not frame_queue.empty():
            try: frame_queue.get_nowait()
            except queue.Empty: pass
        frame_queue.put(data)

        elapsed = time.time() - start
        time.sleep(max(0, interval - elapsed))

threading.Thread(target=capture_and_process, daemon=True).start()

# 8) Flask Ïï±
app = Flask(__name__)

def generate():
    while True:
        frame = frame_queue.get()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    resp = Response(generate(), mimeType='multipart/x-mixed-replace; boundary=frame', direct_passthrough=True)
    resp.headers.update({'Cache-Control':'no-cache, no-store, must-revalidate','Pragma':'no-cache','Expires':'0'})
    return resp

@app.route('/stats')
def stats():
    cpu = psutil.cpu_percent(interval=0.5)
    mem = psutil.virtual_memory()
    temp = None
    try: temp = float(open('/sys/class/thermal/thermal_zone0/temp').read())/1000.0
    except: pass
    sig = None
    try:
        out = subprocess.check_output(['iwconfig','wlan0'], stderr=subprocess.DEVNULL).decode()
        for p in out.split():
            if p.startswith('level='): sig = int(p.split('=')[1])
    except: pass
    return jsonify(cpu_percent=cpu, memory_percent=mem.percent, temperature_c=temp, wifi_signal_dbm=sig)

@app.route('/progress')
def progress():
    if use_file:
        total = int(camera.cap.get(cv2.CAP_PROP_FRAME_COUNT))
    else:
        total = None
    recorded = len(repeat_count)
    remaining = total - recorded if total is not None else None
    return jsonify(total_frames=total, recorded_frames=recorded, remaining_frames=remaining)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
